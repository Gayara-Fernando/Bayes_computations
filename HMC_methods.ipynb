{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9c4574-692a-4a63-9ed3-ee2feaf50121",
   "metadata": {},
   "source": [
    "HMC with https://colab.research.google.com/drive/1YQBSfS1Nb8a9TAMsV1RjWsiErWqXLbrj#scrollTo=FqU8oNOCTcdL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f55b7b-c229-43aa-9bb8-864b21a99490",
   "metadata": {},
   "source": [
    "Hamiltonian Monte Carlo is a variant of MH, but the proposal distribution adds more complexity. MH uses random walks to explore the probability space; as discussed, the likelihoods of current and proposed locations are compared for movement criteria. However, as dimensionality increases, the high likelihood region(s) composes (exponentially) less and less of the total area. In these cases, MH cannot efficiently explore all regions of the distribution and might return samples that are not truly representative of the distribution's shape.\n",
    "\n",
    "HMC instead designs a scheme by which the size of the jump is proportionate to the (negative log) likelihood of the sampler's current position. When close to the high likelihood region(s), it proposes nearby positions; conversely, when far from these high likelihood region(s), larger jumps are proposed. The key is relating position to leap size.\n",
    "\n",
    "HMC loosely uses Hamiltonian mechanics to inform these jumps; namely, differential equations relating position and momentum to each other. Often, differential equations cannot be solved exactly, however various symplectic integration methods (such as leapfrog integration) can closely approximate the solution. These (differential) equations are: (A) the gradient of position with respect to time and (B) the gradient of momentum with respect to time. Leapfrog integration iteratively updates position and momentum in order to estimate where a particle will be given its current position and momentum.\n",
    "\n",
    "Variables and gradients are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78193f1-d483-4da0-ae29-2a4516213ed1",
   "metadata": {},
   "source": [
    "Q = position (parameters in bayes analogy)\n",
    "P = momentum \n",
    "V = potential energy\n",
    "K = kinetic energy\n",
    "T = times\n",
    "dQ/dT = P # position wrt time equals momentum\n",
    "dP/dT = -dV/dQ # momentum wrt time equals potential energy wrt position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd7e90-bea0-4e35-8576-d4ff3e9eb568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c96011-2caf-499d-b7a6-52e53767c440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ecd53-4366-4eb1-9bd1-511cb46dfae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cbfb95-76de-4775-9870-1a99acebd384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6171f-9c2f-42e3-b6f4-42839c07b885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025e3a6-1465-4dad-89ed-e2a9d0a40b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b238a-0b02-4821-9af9-a831aaff33f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594dd6b-b3f9-46a8-b861-2afc6a3e2f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ed720-4079-4ca5-beaf-6eeede539e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e9d6c-7dd0-4dc4-9b70-c53c3fbfd72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9df846-aed0-498a-a812-95d894b19daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078104e6-f2b4-4e18-9736-2c8523ae2094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abea623-9601-457f-8b33-7fa59a7c9a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fae23c-0302-4d5c-b130-7511f6836c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d439f8-13fe-4deb-b6cd-1a188145a494",
   "metadata": {},
   "source": [
    "We are ready for Hamiltonian Monte Carlo methods. We need to specifically understand the NUTs sampler. The following code is from ChapGPT for the implementation of HMC methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e579d095-5b7a-496c-a344-6abf9e110ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bcf804-af5c-4cd2-9de5-5ef4c162be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target distribution (e.g., a standard Gaussian)\n",
    "def target_log_prob(x):\n",
    "    return -0.5 * np.sum(x**2)\n",
    "\n",
    "# Gradient of the target log-probability\n",
    "def grad_log_prob(x):\n",
    "    return -x\n",
    "\n",
    "# Leapfrog integrator\n",
    "def leapfrog(x, p, step_size, num_steps):\n",
    "    x_new = np.copy(x)\n",
    "    p_new = np.copy(p)\n",
    "    \n",
    "    # Half step for momentum at the beginning\n",
    "    p_new -= 0.5 * step_size * grad_log_prob(x_new)\n",
    "    \n",
    "    # Full step for position\n",
    "    for _ in range(num_steps):\n",
    "        x_new += step_size * p_new\n",
    "        # Full step for momentum (except last iteration)\n",
    "        if _ != num_steps - 1:\n",
    "            p_new -= step_size * grad_log_prob(x_new)\n",
    "    \n",
    "    # Half step for momentum at the end\n",
    "    p_new -= 0.5 * step_size * grad_log_prob(x_new)\n",
    "    \n",
    "    return x_new, p_new\n",
    "\n",
    "# Hamiltonian function (H = Kinetic + Potential)\n",
    "def hamiltonian(x, p):\n",
    "    kinetic = 0.5 * np.sum(p**2)  # Kinetic energy from momentum (Gaussian)\n",
    "    potential = -target_log_prob(x)  # Potential energy from target distribution\n",
    "    return kinetic + potential\n",
    "\n",
    "# HMC sampler\n",
    "def hmc_sampler(init_x, step_size, num_steps, num_samples):\n",
    "    samples = []\n",
    "    x = np.copy(init_x)\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Sample momentum from standard normal\n",
    "        p = np.random.randn(*x.shape)\n",
    "        \n",
    "        # Save the current state\n",
    "        current_x = np.copy(x)\n",
    "        current_p = np.copy(p)\n",
    "        \n",
    "        # Perform leapfrog integration\n",
    "        new_x, new_p = leapfrog(x, p, step_size, num_steps)\n",
    "        \n",
    "        # Calculate Hamiltonians\n",
    "        current_H = hamiltonian(current_x, current_p)\n",
    "        new_H = hamiltonian(new_x, new_p)\n",
    "        \n",
    "        # Metropolis-Hastings correction\n",
    "        if np.random.rand() < np.exp(current_H - new_H):\n",
    "            x = new_x  # Accept the new state\n",
    "        # else: reject and keep the current state\n",
    "        \n",
    "        samples.append(np.copy(x))\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbeb4c26-334a-4ebe-9bce-77d53ffb6ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.62109831]\n",
      " [-0.18447019]\n",
      " [-0.64700874]\n",
      " [-0.64700874]\n",
      " [-0.64700874]\n",
      " [ 0.84892764]\n",
      " [ 1.1016588 ]\n",
      " [ 0.87966707]]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "init_x = np.array([0.0])  # Initial position\n",
    "step_size = 0.1  # Step size for leapfrog\n",
    "num_steps = 10  # Number of leapfrog steps\n",
    "num_samples = 1000  # Number of samples to generate\n",
    "\n",
    "# Run HMC\n",
    "samples = hmc_sampler(init_x, step_size, num_steps, num_samples)\n",
    "\n",
    "# Print the first few samples\n",
    "print(samples[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_env_TN_CPU)",
   "language": "python",
   "name": "tfp_env_tn_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
